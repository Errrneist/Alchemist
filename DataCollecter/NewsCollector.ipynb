{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 东方财富网国内新闻数据抓取器\n",
    "## 拂晓工作室\n",
    "### 此程序将爬取某个板块所有最近的新闻并存进CSV！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 参考资料\n",
    "* [1] BeautifulSoup的例子：https://qiita.com/rusarusa/items/d7f014ba80d6fe7a3e07\n",
    "* [2] BeautifulSoup的文档：https://www.cnblogs.com/zhaof/p/6930955.html\n",
    "* [3] How to install BS4 aggressively: https://github.com/ipython/ipython/issues/10684"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入库\n",
    "import urllib\n",
    "import re\n",
    "import pandas as pd\n",
    "import pymysql\n",
    "import os\n",
    "import turicreate\n",
    "import bs4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 新闻板块\n",
    "china = 'cgnjj'  # 国内\n",
    "international = 'cgjjj'  # 国际\n",
    "\n",
    "# 定义基本常量\n",
    "url = 'http://finance.eastmoney.com/news/' + china + '.html' # 主目录地址 更换不同主目录以爬取不同板块内容 (BAD)\n",
    "csv_filepath = '../Datasets/Eastmoney/news/'  # 存储数据文件地址"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功创建包含 25 个页面链接的目录！\n"
     ]
    }
   ],
   "source": [
    "# 创建一个二十五页的list\n",
    "page_list = []\n",
    "counter = 1\n",
    "\n",
    "while counter <= 25:\n",
    "    pageurl = 'http://finance.eastmoney.com/news/' + china\n",
    "    if counter != 1:\n",
    "        pageurl = pageurl + '_' + str(counter) + '.html'\n",
    "        page_list.append(pageurl)\n",
    "    else:\n",
    "        pageurl = pageurl + '.html'\n",
    "        page_list.append(pageurl)\n",
    "    counter += 1\n",
    "    \n",
    "print('成功创建包含 ' + str(len(page_list)) + ' 个页面链接的目录！')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功创建包含 20 个class的目录！\n"
     ]
    }
   ],
   "source": [
    "# 创建一个包含20个class的list\n",
    "counter = 0\n",
    "class_list = []\n",
    "\n",
    "while counter < 20:\n",
    "    class_list.append('newsTr' + str(counter))\n",
    "    counter += 1\n",
    "    \n",
    "print('成功创建包含 ' + str(len(class_list)) + ' 个class的目录！')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 抓取新闻URL函数\n",
    "news_list = []\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 抓取新闻内容函数\n",
    "def getContents(html):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 爬虫抓取网页函数 \n",
    "def getHtml(url):\n",
    "    html = urllib.request.urlopen(url).read()\n",
    "    html = html.decode('gbk')\n",
    "    return html\n",
    "\n",
    "\n",
    "# 抓取网页股票代码函数 (不使用)\n",
    "def getStackCode(html):\n",
    "    s = r'<li><a target=\"_blank\" href=\"http://quote.eastmoney.com/\\S\\S(.*?).html\">'\n",
    "    pat = re.compile(s)\n",
    "    code = pat.findall(html)\n",
    "    return code\n",
    "\n",
    "# 抓取网页所有最近（25）内相关内容的函数\n",
    "def getNewsList(url):\n",
    "    urllist = []\n",
    "    template = r'<li><a '\n",
    "    return urllist"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
