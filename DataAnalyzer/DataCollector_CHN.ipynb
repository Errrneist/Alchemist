{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 新闻数据采集器(国内板块)\n",
    "## [拂晓工作室](https://github.com/Errrneist/Alchemist)\n",
    "* 此程序将对指定股票数据进行收集并整理\n",
    "* 同时创建SFrame友好的CSV文件以及对数据进行清洗"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 参考资料\n",
    "* [1] [Basics of SFrame](https://apple.github.io/turicreate/docs/api/generated/turicreate.SFrame.html#turicreate.SFrame)\n",
    "* [2] [Remove Multiple Substring from String](https://stackoverflow.com/questions/31273642/better-way-to-remove-multiple-words-from-a-string)\n",
    "* [3] [楼老师的Python分析红楼梦](https://zhuanlan.zhihu.com/p/29209681)\n",
    "* [4] [如何使用pyltp包进行中文分词](https://blog.csdn.net/sinat_26917383/article/details/77067515)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hongjunwu/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "# 导入库\n",
    "import urllib\n",
    "import re\n",
    "import pymysql\n",
    "import os\n",
    "import csv\n",
    "import time\n",
    "import datetime\n",
    "import turicreate as tc\n",
    "import turicreate as tc\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 准备阶段\n",
    "* 1. 定义用于搜寻的板块\n",
    "* 2. 创建一个包含25个链接的搜寻目录\n",
    "* 3. 创建一个包含20个Class的搜寻目录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功创建包含 25 个页面链接的目录！\n",
      "成功创建包含 20 个Class的目录！\n"
     ]
    }
   ],
   "source": [
    "# 新闻板块(同时也会加入热门新闻的数据)\n",
    "china = 'cgnjj'  # 国内\n",
    "international = 'cgjjj'  # 国际\n",
    "\n",
    "# 定义基本常量\n",
    "url = 'http://finance.eastmoney.com/news/' + china + '.html' # 主目录板块\n",
    "\n",
    "# 创建一个二十五页的list\n",
    "page_list = []\n",
    "counter = 1\n",
    "\n",
    "while counter <= 25:\n",
    "    pageurl = 'http://finance.eastmoney.com/news/' + china\n",
    "    if counter != 1:\n",
    "        pageurl = pageurl + '_' + str(counter) + '.html'\n",
    "        page_list.append(pageurl)\n",
    "    else:\n",
    "        pageurl = pageurl + '.html'\n",
    "        page_list.append(pageurl)\n",
    "    counter += 1\n",
    "    \n",
    "print('成功创建包含 ' + str(len(page_list)) + ' 个页面链接的目录！')\n",
    "\n",
    "# 创建一个包含20个class的list\n",
    "counter = 0\n",
    "class_list = []\n",
    "\n",
    "while counter < 20:\n",
    "    class_list.append('newsTr' + str(counter))\n",
    "    counter += 1\n",
    "    \n",
    "print('成功创建包含 ' + str(len(class_list)) + ' 个Class的目录！')\n",
    "# print(class_list)  # Debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 获得所有文章的链接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------获取所有文章超链接程序-----------------\n",
      "分析任务开始！\n"
     ]
    },
    {
     "ename": "IncompleteRead",
     "evalue": "IncompleteRead(41974 bytes read, 41991 more expected)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIncompleteRead\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-298c3d5901f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mhtml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"lxml\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0meach_url\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    460\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m                     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_safe_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mIncompleteRead\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_close_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36m_safe_read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    612\u001b[0m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMAXAMOUNT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 614\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mIncompleteRead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    615\u001b[0m             \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m             \u001b[0mamt\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIncompleteRead\u001b[0m: IncompleteRead(41974 bytes read, 41991 more expected)"
     ]
    }
   ],
   "source": [
    "# 初始化urllist\n",
    "urllist = []\n",
    "year = '2018'  # Separate parameter\n",
    "counter = 1\n",
    "\n",
    "# 创造urllist\n",
    "print('-----------------获取所有文章超链接程序-----------------')\n",
    "print('分析任务开始！')\n",
    "for url in page_list:\n",
    "    req = urllib.request.Request(url)\n",
    "    response = urllib.request.urlopen(req)\n",
    "    html = response.read()\n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "    for each_url in soup.find_all('a', href=True):\n",
    "        if 'http://finance.eastmoney.com/news/' in each_url['href']:\n",
    "            if year in each_url['href']:\n",
    "                urllist.append(each_url['href'])   \n",
    "    print('第' + str(counter) + '页分析完成！现在一共获得了' + str(len(urllist)) + '篇文章的链接！')\n",
    "    counter += 1\n",
    "\n",
    "print('全部分析完成！正在查重...')\n",
    "urllist = list(set(urllist))\n",
    "print('任务完成！共获得了' + str(len(urllist)) + '篇文章的链接！')\n",
    "print('---------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 将各个网页的资料抓取进SFrame\n",
    "* 1. 新建用于抓取的函数\n",
    "* 2. 实施抓取\n",
    "* 3. 清洗数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 清洗数据的词库\n",
    "banned_info = ['责任编辑','原标题']\n",
    "banned_words = ['摘要\\n', '\\n', '\\r','\\u3000','（中国新闻网）',\n",
    "                '来源','以下简称', '（新华社）', '>>>', \n",
    "                '商务微新闻带你一图了解！','-', '经济日报', '中国经济网',\n",
    "                '附件：', '>>>>', '>>', '>>>>>', '（新华网）', \n",
    "                '（第一财经）', '据新华社报道，', '▼', '▲']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 抓取新闻URL函数\n",
    "def collectNews(news, url, counter):\n",
    "    # 准备请求数据\n",
    "    req = urllib.request.Request(url)\n",
    "    # print('请求链接连接成功!')\n",
    "    response = urllib.request.urlopen(req)\n",
    "    # print('收到反馈信号！')\n",
    "    html = response.read()\n",
    "    # print('HTML生成完毕！')\n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "    # print('SOUP创建完成！')\n",
    "    \n",
    "    # 获得文章的发表时间 \n",
    "    time = soup.find(class_=\"time\").get_text()\n",
    "    # print('时间获取完毕！')\n",
    "    \n",
    "    # 获得文章的标题\n",
    "    title = soup.find('h1').get_text()\n",
    "    \n",
    "    # 鉴于有的文章将标题重复一遍 加入洗词库把标题洗掉\n",
    "    banned_words.append('【' + title + '】')\n",
    "    \n",
    "    # 获得文章的内容\n",
    "    content = soup.find(id=\"ContentBody\").get_text() \n",
    "    \n",
    "    # 清洗文章末尾编辑原文信息    \n",
    "    for banned_information in banned_info:\n",
    "        if banned_information in content:\n",
    "            content = content[0:re.search(banned_information, content).span()[0]-1].strip()\n",
    "        \n",
    "    # 清洗文章中冗余文字\n",
    "    for banned_word in banned_words:\n",
    "        content = content.replace(banned_word, '')\n",
    "    # print('文章内容获取完成！')\n",
    "    \n",
    "    # 将标题从洗词库中去除\n",
    "    banned_words.remove(title)\n",
    "\n",
    "    # 获取相关主题\n",
    "    related_stocks = []\n",
    "    for each in soup.find_all(class_='keytip'): \n",
    "        related_stocks.append(each.get_text())\n",
    "    \n",
    "    # 相关主题查重\n",
    "    related_stocks = list(set(related_stocks))\n",
    "    # print('相关主题单获取完成！')         \n",
    "    \n",
    "    # 写入SFrame\n",
    "    temp_sframe = tc.SFrame({'year':[str(time[0:4])],\n",
    "                             'month':[str(time[5:7])],\n",
    "                             'day':[str(time[8:10])],\n",
    "                             'date':[str(time[0:4]) + str(time[5:7]) + str(time[8:10])],\n",
    "                             'title':[title],\n",
    "                             'contents':[content], \n",
    "                             'related':[related_stocks]})\n",
    "    news = news.append(temp_sframe)\n",
    "    # print('SFrame写入完成!')\n",
    "    \n",
    "    # 释放内存\n",
    "    del(req, response, html, soup, time, content, related_stocks)\n",
    "    \n",
    "    # 刷新计数 \n",
    "    counter += 1\n",
    "    # print('计数刷新完成！')\n",
    "    # print('页面数据获取完毕！')\n",
    "    return news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在获取第1篇文章.\n",
      "正在获取第2篇文章.\n",
      "正在获取第3篇文章.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-0cba4fb81f4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'正在获取第'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'篇文章.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# print('---------------------------------------------')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mnews\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollectNews\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnews\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meach_article\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mcounter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-ba7351f84870>\u001b[0m in \u001b[0;36mcollectNews\u001b[0;34m(news, url, counter)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# print('收到反馈信号！')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mhtml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;31m# print('HTML生成完毕！')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"lxml\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    460\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m                     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_safe_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mIncompleteRead\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_close_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36m_safe_read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    610\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMAXAMOUNT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mIncompleteRead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 初始化计数器\n",
    "counter = 1\n",
    "\n",
    "# 获取总任务数\n",
    "total = len(urllist)\n",
    "\n",
    "# 创建SFrame\n",
    "news = tc.SFrame({'year':['0000'],'month':['00'],'day':['00'],'date':['00000000'],'title':['Null Title'],'contents':['Null Contents'],'related':[['Null', 'Null']]})\n",
    "\n",
    "# 下载数据\n",
    "for each_article in urllist:\n",
    "    # print('=============================================')\n",
    "    print('正在获取第' + str(counter) + '篇文章，共' + str(total) + '篇.')\n",
    "    # print('---------------------------------------------')\n",
    "    news = collectNews(news, each_article, counter) \n",
    "    counter += 1\n",
    "    \n",
    "print('获取完毕！共获取了' + len(news['title']) + '篇文章!')\n",
    "\n",
    "# 删除占位符\n",
    "news = news[1:len(news['title'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存数据\n",
    "filepath = '../DataSets/Eastmoney/China/'\n",
    "date = '20' + str(datetime.datetime.now().strftime(\"%y%m%d-%H%M\"))\n",
    "news.save(filepath + date + '.csv', format='csv')\n",
    "print('成功保存数据文件！数据路径：' + filepath + date + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
